---
title: "zipcode2features"
author: "Michael Mullarkey"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
      smooth_scroll: no
geometry: margin=0.50in
---

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
## setting working directory
opts_knit$set(root.dir = "/Users/Carbonite/Documents/Github_R/zipcode2features") ## Will need to change across computers
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, warning = FALSE, message = FALSE, include = FALSE)

```

```{r loading packages}

if(!require(tidymodels)){install.packages('tidymodels')}
library(tidymodels)
if(!require(readr)){install.packages('readr')}
library(readr)
if(!require(broom.mixed)){install.packages('broom.mixed')}
library(broom.mixed)
if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)
if(!require(nycflights13)){install.packages('nycflights13')}
library(nycflights13)
if(!require(skimr)){install.packages('skimr')}
library(skimr)
if(!require(modeldata)){install.packages('modeldata')}
library(modeldata)
if(!require(ranger)){install.packages('ranger')}
library(ranger)
if(!require(vip)){install.packages('vip')}
library(vip)
if(!require(gt)){install.packages('gt')}
library(gt)
if(!require(ggthemes)){install.packages('ggthemes')}
library(ggthemes)
if(!require(xgboost)){install.packages('xgboost')}
library(xgboost)
if(!require(keras)){install.packages('keras')}
library(keras)
if(!require(furrr)){install.packages('furrr')}
library(furrr)
if(!require(kernlab)){install.packages('kernlab')}
library(kernlab)
if(!require(mlbench)){install.packages('mlbench')}
library(mlbench)
if(!require(scales)){install.packages('scales')}
library(scales)
if(!require(tidyposterior)){install.packages('tidyposterior')}
library(tidyposterior)
if(!require(rstanarm)){install.packages('rstanarm')}
library(rstanarm)
if(!require(tictoc)){install.packages('tictoc')}
library(tictoc)
# library(devtools)
# devtools::install_github("abresler/nbastatR")
library(nbastatR)
if(!require(heatmaply)){install.packages('heatmaply')}
library(heatmaply)
if(!require(ggmosaic)){install.packages('ggmosaic')}
library(ggmosaic)
if(!require(splines)){install.packages('splines')}
library(splines)
if(!require(doMC)){install.packages('doMC')}
library(doMC)
if(!require(glue)){install.packages('glue')}
library(glue)
if(!require(stacks)){install.packages('stacks')}
library(stacks)
if(!require(janitor)){install.packages('janitor')}
library(janitor)
if(!require(future)){install.packages('future')}
library(future)
if(!require(reticulate)){install.packages('reticulate')}
library(reticulate)
if(!require(furrr)){install.packages('furrr')}
library(furrr)
if(!require(tuber)){install.packages('tuber')}
library(tuber)
if(!require(tidytext)){install.packages('tidytext')}
library(tidytext)
if(!require(topicmodels)){install.packages('topicmodels')}
library(topicmodels)
if(!require(wordcloud)){install.packages('wordcloud')}
library(wordcloud)
if(!require(reshape2)){install.packages('reshape2')}
library(reshape2)
if(!require(youtubecaption)){install.packages('youtubecaption')}
library(youtubecaption)
if(!require(textrecipes)){install.packages('textrecipes')}
library(textrecipes)
if(!require(stopwords)){install.packages('stopwords')}
library(stopwords)
if(!require(hardhat)){install.packages('hardhat')}
library(hardhat)
if(!require(poissonreg)){install.packages('poissonreg')}
library(poissonreg)
if(!require(remotes)){install.packages('remotes')}
library(remotes)
# remotes::install_github('jorvlan/raincloudplots')
library(raincloudplots)
if(!require(DescTools)){install.packages('DescTools')}
library(DescTools)
if(!require(readxl)){install.packages('readxl')}
library(readxl)
if(!require(modeest)){install.packages('modeest')}
library(modeest)
if(!require(psych)){install.packages('psych')}
library(psych)
# install_local("DTVEM_1.0010.tar.gz") # http://www.nicholasjacobson.com/project/dtvem/
library(DTVEM)
# Loading DTVEM dependencies
if(!require(mgcv)){install.packages('mgcv')}
library(mgcv)
if(!require(zoo)){install.packages('zoo')}
library(zoo)
if(!require(OpenMx)){install.packages('OpenMx')}
library(OpenMx)
if(!require(imputeTS)){install.packages('imputeTS')}
library(imputeTS)
if(!require(tfdatasets)){install.packages('tfdatasets')}
library(tfdatasets)
if(!require(rlang)){install.packages('rlang')}
library(rlang)
if(!require(RANN)){install.packages('RANN')}
library(RANN)
if(!require(baguette)){install.packages('baguette')}
library(baguette)
if(!require(rules)){install.packages('rules')}
library(rules)
if(!require(timetk)){install.packages('timetk')}
library(timetk)
if(!require(tidyquant)){install.packages('tidyquant')}
library(tidyquant)
if(!require(tsibble)){install.packages('tsibble')}
library(tsibble)
if(!require(feasts)){install.packages('feasts')}
library(feasts)
if(!require(dtw)){install.packages('dtw')}
library(dtw)
if(!require(parallelDist)){install.packages('parallelDist')}
library(parallelDist)
if(!require(pheatmap)){install.packages('pheatmap')}
library(pheatmap)
if(!require(diffdf)){install.packages('diffdf')}
library(diffdf)
if(!require(tableone)){install.packages('tableone')}
library(tableone)
if(!require(tableone)){install.packages('tableone')}
library(tableone)
if(!require(corrr)){install.packages('corrr')}
library(corrr)
if(!require(Amelia)){install.packages('Amelia')}
library(Amelia)
if(!require(MOTE)){install.packages('MOTE')}
library(MOTE)
if(!require(zipcodeR)){install.packages('zipcodeR')}
library(zipcodeR)
if(!require(openintro)){install.packages('openintro')}
library(openintro)
if(!require(readxl)){install.packages('readxl')}
library(readxl)
if(!require(haven)){install.packages('haven')}
library(haven)

## Let's set our number of cores for this document (May differ across computers)

registerDoMC(cores = 7)

```

```{r reading in the data}

## Reading in baseline data

# Have to skp 3 rows and assign no names since the Qualtrics reads the data in super weird

zip2feat_data <- read_csv("zipcode2features_example_data.csv")

glimpse(zip2feat_data)


```

```{r figure out reverse zip code search}

zip_code_initial_features <- reverse_zipcode(zip2feat_data$zip_code)

## Let's try reading in some county level data

# devtools::install_github("asmae-toumi/MSVI")
library(MSVI)

## Let's check AHRF data file

ahrf %>% 
  filter(year_represented_by_variable == "2016") %>% 
  group_by(state, variable) %>% 
  count()

glimpse(ahrf)

ahrf %>% 
  group_by(category) %>% 
  count()

## Let's try to join clincians per 100k county population based on county, this doesn't work! All NAs

zip_code_updated_ahrf_features <- zip_code_initial_features %>% 
  left_join(ahrf, by = "county")

glimpse(zip_code_updated_ahrf_features)

## Checking the county variable in initial features

zip_code_initial_features %>% 
  group_by(county) %>% 
  tally()

## When we do this, no rows, so the matching across dataframes won't work by default

ahrf %>%
  filter(county %in% zip_code_initial_features$county) %>% 
  group_by(county) %>% 
  tally()

zip_code_initial_features %>%
  filter(county %in% ahrf$county) %>% 
  group_by(county) %>% 
  tally()

```

```{r creating a county variable that can match across data frames}

## Looking at the different counties in initial data

zip_code_initial_features %>% 
  group_by(county) %>% 
  tally()

## Looking for something like those counties in the ahrf data

ahrf %>% 
  filter(str_detect(county, "Allegheny")) %>% 
  print()

## Creating a new county variable in initial data to match the county variable in the ahrf

zip_code_updated_ahrf_style_county <- zip_code_initial_features %>% 
  mutate(county_ahrf = str_replace(county, " County","")) %>% 
  print()

```

```{r matching just on county and ending up with non na values}

## Ok, can we match and get accurate data based off of the is new county variable?

zip_code_updated_ahrf_features <- zip_code_updated_ahrf_style_county %>% 
  left_join(ahrf, by = c("county_ahrf" = "county"))

## We get non NA values if we do this join

glimpse(zip_code_updated_ahrf_features)

```

```{r running a test to see whether the data matching was accurate and discovering not so much}

## Let's write a test to make sure the values we're getting from the AHRF data are correctly matched to the initial features?

## Visual inspection shows that across dataframes, at least one county is matched to the correct state

zip_code_updated_ahrf_features %>% 
  filter(county_ahrf == "Allegheny") %>% 
  print()

## Can we figure out programmatically if across all the counties that match across dataframes, do all of those also match on state?

ahrf_in_initial_zip_features <- ahrf %>%
  filter(county %in% zip_code_updated_ahrf_features$county_ahrf) %>% 
  dplyr::select(state, county) %>%
  distinct(county, .keep_all = T) %>% 
  arrange(county) %>% 
  print()

zip_code_initial_features_reduced_for_state_test <- zip_code_updated_ahrf_features %>% 
  filter(county_ahrf %in% ahrf$county) %>% 
  dplyr::select(state = state.x, county = county_ahrf) %>%
  mutate(state = abbr2state(state)) %>% 
  distinct(county, .keep_all = T) %>% 
  arrange(county) %>% 
  print()

diffdf(ahrf_in_initial_zip_features, zip_code_initial_features_reduced_for_state_test)

```

```{r figuring out that the issue is having the same county name in different states}

## Doing visual inspection based on the differences we observe, and we see that our mistmatches are due to having the same county name in different states

ahrf_in_initial_zip_features %>% 
  slice(7,10,12,15,16,17,18,25,28,33) %>% 
  bind_cols(zip_code_initial_features_reduced_for_state_test %>% slice(7,10,12,15,16,17,18,25,28,33))

```

```{r fixing that state county issue and demonstrating a function that can undo the name collisions we have based on an earlier join}
## Ok, given that let's join based not only on county, but also on state

## Let's create a state variable that matches the AHRF data in our initial feature set

zip_code_initial_features_county_and_state_ahrf <- zip_code_updated_ahrf_features %>%
  mutate(state_ahrf = abbr2state(state.x))

## Now let's create a function that removes the .y for variables that collide based on having the same names due to the earlier join creating different data/columns since some of the counties were mismatched/wrong

remove_dot_y_at_var_end <- function(.data){
  
  non_dot_y_vars <- .data %>% 
    dplyr::select(-ends_with(".y"))

  dot_y_vars <- .data %>%
    dplyr::select(ends_with(".y")) %>%
    rename_with(~str_replace(.x, "\\.y",""))
  
  .data <- non_dot_y_vars %>% 
    bind_cols(dot_y_vars)

}

zip_code_updated_ahrf_features <- zip_code_initial_features_county_and_state_ahrf %>% 
  left_join(ahrf, by = c("county_ahrf" = "county", "state_ahrf" = "state")) %>% 
  dplyr::select(-ends_with(".x")) %>% 
  distinct(zipcode, .keep_all = T) %>% 
  remove_dot_y_at_var_end()

glimpse(zip_code_updated_ahrf_features)

```

```{r running the accuraacy test again to confirm we have fixed that problem}

## Run the same test again to see if we've fixed the problem

## Can we figure out programmatically if across all the counties that match across dataframes, do all of those also match on state? Now they do!

ahrf_in_initial_zip_features <- ahrf %>%
  filter(county %in% zip_code_updated_ahrf_features$county_ahrf) %>% 
  dplyr::select(state, county) %>%
  distinct(county, .keep_all = T) %>% 
  arrange(county, state) %>% 
  print()

zip_code_initial_features_reduced_for_state_test <- zip_code_updated_ahrf_features %>% 
  filter(county_ahrf %in% ahrf$county) %>% 
  dplyr::select(state, county = county_ahrf) %>%
  distinct(county, .keep_all = T) %>% 
  arrange(county, state) %>% 
  print()

diffdf(ahrf_in_initial_zip_features, zip_code_initial_features_reduced_for_state_test)


```
```{r integrating whether there is a mental health care provider shortage into our data}

## Now we read in the mental healthcare shortage provider data

hpsa_mh_data <- read_excel("hpsa_mh_data_feb_2021.xlsx") %>% 
  clean_names()

## We see that this isn't 5 digit zipcode, also contains other specifiers

glimpse(hpsa_mh_data)

## We'll want to separate those into different columns and drop the extra info we can't use https://tidyr.tidyverse.org/reference/separate.html

hpsa_mh_data_zipcode <- hpsa_mh_data %>% 
  separate(zip, c("zipcode","filler")) %>% 
  dplyr::select(-filler) %>% 
  print()

## Now want to see if there are/how many redundant zip codes there are

hpsa_mh_data_zipcode_mean_hpsa %>% 
  group_by(zipcode) %>% 
  tally() %>% 
  filter(n >=2)

## There are a decent number of duplicate zipcodes in this data now, so we're going to take some means across zipcodes

## We have to average hpsa_score, figure out what we want from hpsa_status/rural status when zip codes disagree

hpsa_mh_data_zipcode_aggregate_hpsa <- hpsa_mh_data_zipcode %>% 
  group_by(zipcode) %>% 
  mutate(mean_hpsa_score = mean(hpsa_score, na.rm = T)) %>% 
  ungroup() %>% 
  distinct(zipcode, .keep_all = T) %>% 
  dplyr::select(zipcode, mean_hpsa_score)

## Can now merge this with our initial features + AHRF data

zip_code_updated_hpsa <- zip_code_updated_ahrf_features %>% 
  left_join(hpsa_mh_data_zipcode_aggregate_hpsa, by = "zipcode") %>% 
  mutate(hpsa_designated_area = case_when(
    
    is.na(mean_hpsa_score) ~ "Not Designated",
    TRUE ~ "Designated"
)) %>% 
  print()

```

```{r integrating county level data on explicit feeling thermometers toward white and black people from project implicit}

proj_implicit <- read_sav("Race.IAT.public.2020.sav") %>% 
  clean_names()

glimpse(proj_implicit)

proj_implicit_reduced <- proj_implicit %>% 
  dplyr::select(state, twhite_0to10,tblack_0to10, d_biep_white_good_all) %>% 
  mutate(state = as.character(state),
         twhite_0to10 = as.numeric(twhite_0to10),
         tblack_0to10 = as.numeric(tblack_0to10),
         d_biep_white_good_all = as.numeric(d_biep_white_good_all), 
    state = case_when(
    
    state == "" ~ NA_character_,
    TRUE ~ state
    
  )) %>% 
  filter(!is.na(state) & !is.na(twhite_0to10) & !is.na(tblack_0to10) & !is.na(d_biep_white_good_all)) %>% 
  group_by(state) %>% 
  mutate(across(
    .cols = is.numeric,
    .fns = list(mean = mean, sd = sd, median = median, max = max, min = min, kurtosis = kurtosi, skew = skew),
    .names = "{col}_{fn}")) %>%
  distinct(state, .keep_all = T) %>% 
  dplyr::select(-twhite_0to10,-tblack_0to10) %>% 
  mutate(t_diff_mean_white_and_black = twhite_0to10_mean - tblack_0to10_mean) %>% 
  mutate(state = abbr2state(state)) %>% # Had to do this since abbreviations weren't matching up
  arrange(state) %>% 
  ungroup()

glimpse(proj_implicit_reduced)

## Now merging with features already engineered

zip_code_updated_project_implicit <- zip_code_updated_hpsa %>% 
  left_join(proj_implicit_reduced, by = ("state" = "state"))

glimpse(zip_code_updated_project_implicit)

```


```{r}

## Future dataset resources

# https://piktochart.com/blog/100-data-sets/

# https://www.freecodecamp.org/news/https-medium-freecodecamp-org-best-free-open-data-sources-anyone-can-use-a65b514b0f2d/

```

